LabStreamingLayer (LSL) is a library of tools that enable network based inter-device communication, data acquisition and temporal synchronization for scientific purposes. It is open source and has interfaces with multiple programming languages such as Python, Matlab, C++, and C#. 

It has extensive documentation online [here](https://github.com/sccn/labstreaminglayer) and [here](https://labstreaminglayer.readthedocs.io/info/intro.html) so we will not go into much details here. 

What is important to know is: 
* LSL can create _inlets_ to receive or _outlets_ to send data over network _streams_
* Any computer on the network can connect to a _stream_ and listen in
* It has built-in functions to align high precision clocks across computers and is expected to have sub-millisecond accuracy on local networks
* Many _Apps_ are available to directly interface with many acquisition devices such as: Eyelink, Tobii, SMI and Pupil eye trackers, OpenVR and wiimotes, as well as a disk recording app (LabRecorder). 

Individual streams are defined by multiple parameters: 
-	Name: stream name to be discoverable over the network.
-	Content type: kind of data sent over the network, such as EEG, Markers (i.e. strings), Unity, …
-	Number of channels: data will be a channel x sample array
-	Rate: Irregular (0) or any value in Hz
-	Channel format: cf_string, cf_float32, cf_double64, cf_int32, …
-	Unique ID: unique identifier from the source/device

All these parameters need to be defined when creating an outlet stream, for example: 
-	Name: UnityVR_FrameData
-	Content type: Unity
-	Number of channels: 1
-	Rate: 0
-	Channel format: cf_string
-	Unique ID: framedata123

This stream can then be found (i.e. resolved) using any combination of Name, Content Type or Unique ID, and registered to (i.e. create an inlet) and start acquiring data. 