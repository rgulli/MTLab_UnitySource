This section will describe the life cycle of Unity scripts execution and how it updates the GameObjects. 

## Frame and Update Rates
Since Unity is a VR/video game engine, its core operation revolves around individual frames. There is no point in wasting resources to compute behaviors that will never make it to screen and therefore never be experienced by the subject. This is why we limit the frame rate of the engine to match the current monitor's refresh rate, by enabling Vertical Synchronization or VSync. That way, the engine only computes frames that will entirely be displayed and we gain proper control of stimuli presentation. 

![VSync](https://github.com/Doug1983/MTLab_UnitySource/blob/master/Documentation/img/VSync.jpg)

As a side note, some processing requires independence from frame rates. The most important example is physics computations. Indeed, the falling speed of an object needs to be computed independently of frame rate, if not, things will fall faster with increasing frame rates, or will appear to slow down and speed up again if there is a sudden drop in frame rate. 

To this end, the Unity engine has two main loops, operating independently:
* [FixedUpdate](https://docs.unity3d.com/ScriptReference/MonoBehaviour.FixedUpdate.html): as the name implies, updates at a fixed and frame independent rate. The default value is 50 Hz or 20 ms timesteps. It can be changed via `Edit > Project Settings > Time > Fixed Timestep`. 
* [Update](https://docs.unity3d.com/ScriptReference/MonoBehaviour.Update.html): the main GameObject update call. Is executed on every frame, which means that the time interval between each call is variable and dependent on computing resources and current engine demands. 

For our specific use, we don't use the FixedUpdate loop but it is important to understand why it's there, especially when looking at the following sections where we explore the script execution order and life cycles. 

## Script Execution Order
The following figure comes from the [Unity documentation](https://docs.unity3d.com/Manual/ExecutionOrder.html) and shows the order at which specific functions are called. We will focus on the most important ones afterwards. 

![Flow chart](https://docs.unity3d.com/uploads/Main/monobehaviour_flowchart.svg)

#### OnEnable and Start
[OnEnable](https://docs.unity3d.com/ScriptReference/MonoBehaviour.OnEnable.html) is executed as soon as an object becomes active, whereas [Start](https://docs.unity3d.com/ScriptReference/MonoBehaviour.Start.html) is executed **once** on the same frame it becomes enabled, but before any calls to the main Update function. 

The important points here are that OnEnable is executed before Start. When launching a game all the GameObjects will be "enabled" but this won't happen at exactly the same time for all of them, so in situations where a GameObject initialization script requires other objects to already be initialized, separating them OnEnable and Start is a safe way to achieve this. 

An example of this could be a `GameController` class generating a list of all GameObjects in the current scene and a different `Networking` class responsible for sending this list to a specific server. Since there are no guarantees that the `Networking` class OnEnable will be executed after the `GameController`'s, we could put the script to send the data in the Networking Start function. 

#### Update and LateUpdate
The "Game logic" section of the graph highlights the frame processing part. The [Update](https://docs.unity3d.com/ScriptReference/MonoBehaviour.Update.html) function is executed every frame for each class deriving from MonoBehaviour. Again, since the Update functions of all GameObjects are not executed simultaneously, if further processing is required **after** all Update computations are done, but before rendering, then they should be implemented in the [LateUpdate](https://docs.unity3d.com/ScriptReference/MonoBehaviour.LateUpdate.html) call. 

Importantly, the GameObjects Update function is called **before** the Update function of the [[Animator|2.3.2-Unity-Editor#animator]] state system. The order of script execution is then Update -> State system Update -> LateUpdate.

To go back to our previous example, the `GameController` Update could compute the new positions of GameObjects, then the Animator state system checks these values to trigger the state changes accordingly, and finally, the `Networking` class waits until all the GameObjects and states have been updated (i.e. LateUpdate) before sending the data to the server.

#### Rendering
The important thing to understand is that nothing gets updated after LateUpdate. The scene is now static and the frame rendering begins. Rendering simply means that the graphics card is calculating what each pixel looks like based on the position, geometry, texture and lighting of individual 3D objects in the scene. Computations include generating highlights and shadows from the light sources illuminating objects. It is then obvious that 3D objects shouldn't move past this point as there will be inconsistencies between objects and their shadows. 

Once an entire frame is rendered, it is sent to a frame buffer on the GPU to wait for the next screen refresh, or flip, time. Typically frame buffers hold between 1 and 3 frames and this can be configured in your graphics card options. The longer the buffer the longer the latency between a frame being computed and the same frame being displayed on screen. For example a 3 frame buffer @ 60Hz would mean a delay >= 50 ms. 

#### yield WaitForEndOfFrame
While [WaitForEndOfFrame](https://docs.unity3d.com/ScriptReference/WaitForEndOfFrame.html) is not a function, but needs to be integrated in a [coroutine](https://docs.unity3d.com/ScriptReference/Coroutine.html), it is highly important as it is the absolute latest point we can access via script before a frame is pushed to the frame buffer. It is highly important to minimize latency when synchronizing with other behavioral or electrophysiological acquisition devices. 







